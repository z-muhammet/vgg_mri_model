{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install kagglehub torch torchvision numpy pillow matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"orvile/brain-cancer-mri-dataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"orvile/brain-cancer-mri-dataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"brain_glioma\": \"0_glioma\",\n",
    "    \"brain_menin\": \"1_menin\",\n",
    "    \"brain_tumor\": \"2_tumor\"\n",
    "}\n",
    "SOURCE_DIR = path\n",
    "DEST_DIR = \"dataset\"\n",
    "random.seed(42)\n",
    "\n",
    "def ensure_dir(p):\n",
    "    if not os.path.exists(p):\n",
    "        os.makedirs(p)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for label in LABEL_MAP.values():\n",
    "        ensure_dir(os.path.join(DEST_DIR, split, label))\n",
    "\n",
    "def split_and_copy(class_name, train_ratio=0.7, val_ratio=0.15):\n",
    "    src_folder = os.path.join(SOURCE_DIR, class_name)\n",
    "    label_folder = LABEL_MAP[class_name]\n",
    "    files = [f for f in os.listdir(src_folder) if f.lower().endswith(\".jpg\")]\n",
    "    random.shuffle(files)\n",
    "    total = len(files)\n",
    "    train_split = int(train_ratio * total)\n",
    "    val_split = int(val_ratio * total)\n",
    "    train_files = files[:train_split]\n",
    "    val_files = files[train_split:train_split + val_split]\n",
    "    test_files = files[train_split + val_split:]\n",
    "    for fname in train_files:\n",
    "        shutil.copy(os.path.join(src_folder, fname), os.path.join(DEST_DIR, \"train\", label_folder, fname))\n",
    "    for fname in val_files:\n",
    "        shutil.copy(os.path.join(src_folder, fname), os.path.join(DEST_DIR, \"val\", label_folder, fname))\n",
    "    for fname in test_files:\n",
    "        shutil.copy(os.path.join(src_folder, fname), os.path.join(DEST_DIR, \"test\", label_folder, fname))\n",
    "    print(f\"{class_name}: {len(train_files)} train, {len(val_files)} val, {len(test_files)} test\")\n",
    "\n",
    "for cls in LABEL_MAP:\n",
    "    split_and_copy(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "SOURCE_ROOT = \"dataset\"\n",
    "DEST_ROOT = \"preprocessed_data\"\n",
    "TARGET_SIZE = (256, 256)\n",
    "LOG_PATH = \"logs/resize_and_normalize.log\"\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def log(message):\n",
    "    timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "    full_message = f\"{timestamp} {message}\"\n",
    "    print(full_message)\n",
    "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_message + \"\\n\")\n",
    "\n",
    "def process_and_save_image(src_path, dest_path):\n",
    "    try:\n",
    "        image = Image.open(src_path).convert(\"RGB\")\n",
    "        image = image.resize(TARGET_SIZE)\n",
    "        image_array = np.asarray(image).astype(np.float32) / 255.0\n",
    "        np.save(dest_path, image_array)\n",
    "        log(f\"[OK] {src_path} → {dest_path}\")\n",
    "    except Exception as e:\n",
    "        log(f\"[ERROR] {src_path} → {e}\")\n",
    "\n",
    "def process_folder(split):\n",
    "    source_dir = os.path.join(SOURCE_ROOT, split)\n",
    "    dest_dir = os.path.join(DEST_ROOT, split)\n",
    "    for class_name in os.listdir(source_dir):\n",
    "        src_class_dir = os.path.join(source_dir, class_name)\n",
    "        dst_class_dir = os.path.join(dest_dir, class_name)\n",
    "        ensure_dir(dst_class_dir)\n",
    "        for filename in os.listdir(src_class_dir):\n",
    "            if filename.lower().endswith(\".jpg\"):\n",
    "                src_file = os.path.join(src_class_dir, filename)\n",
    "                dst_file = os.path.join(dst_class_dir, filename.replace(\".jpg\", \".npy\"))\n",
    "                process_and_save_image(src_file, dst_file)\n",
    "\n",
    "ensure_dir(\"logs\")\n",
    "with open(LOG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== Resize & Normalize Log Başladı ===\\n\")\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    process_folder(split)\n",
    "log(\"=== Tüm işlemler tamamlandı ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "class CustomTumorDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_training=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.is_training = is_training\n",
    "        self.samples = []\n",
    "\n",
    "        self.class_names = ['0_glioma', '1_menin', '2_tumor']\n",
    "        self.class_to_idx = {name: int(name.split('_')[0]) for name in self.class_names}\n",
    "        self.classes = self.class_names\n",
    "\n",
    "        if transform is None:\n",
    "            if is_training:\n",
    "                self.transform = transforms.Compose([\n",
    "                    transforms.Resize((256, 256)),\n",
    "                    transforms.RandomHorizontalFlip(p=0.7),\n",
    "                    transforms.RandomVerticalFlip(p=0.5),\n",
    "                    transforms.RandomRotation(degrees=20),\n",
    "                    transforms.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.85, 1.15), shear=10),\n",
    "                    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "                    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = transforms.Compose([\n",
    "                    transforms.Resize((256, 256)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "\n",
    "        for class_name in self.class_names:\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            label = self.class_to_idx[class_name]\n",
    "\n",
    "            for file_name in os.listdir(class_path):\n",
    "                if file_name.lower().endswith(('.npy')):\n",
    "                    file_path = os.path.join(class_path, file_name)\n",
    "                    self.samples.append((file_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        if file_path.lower().endswith('.npy'):\n",
    "            image = np.load(file_path)\n",
    "            image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "        else:\n",
    "            image = Image.open(file_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.squeeze(x).view(b, c)\n",
    "        y = self.excitation(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_se=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        self.se = SEBlock(out_channels) if use_se else nn.Identity()\n",
    "        self.residual = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.se(self.conv(x)) + self.residual(x)\n",
    "\n",
    "class VGGCustom(nn.Module):\n",
    "    def __init__(self, num_classes: int = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            ConvBlock(3, 29),\n",
    "            ConvBlock(29, 58),\n",
    "            ConvBlock(58, 115),\n",
    "            nn.Dropout2d(0.05),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            ConvBlock(115, 58),\n",
    "            ConvBlock(58, 29),\n",
    "            ConvBlock(29, 29),\n",
    "            nn.Dropout2d(0.05),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            ConvBlock(29, 58),\n",
    "            ConvBlock(58, 115),\n",
    "            ConvBlock(115, 230),\n",
    "            nn.Dropout2d(0.05),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.blocks = nn.ModuleList([self.block1, self.block2, self.block3])\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(230 * 4 * 4, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 512),         nn.BatchNorm1d(512),  nn.GELU(), nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),          nn.BatchNorm1d(256),  nn.GELU(), nn.Dropout(0.05),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "        self.freeze_blocks_until(0)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def freeze_blocks_until(self, last_open_idx: int):\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            req_grad = i <= last_open_idx\n",
    "            for p in blk.parameters():\n",
    "                p.requires_grad = req_grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        x = self.avgpool(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "from collections import Counter\n",
    "import os, time, torch, matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms.v2 as T\n",
    "from dataset.custom_dataset import CustomTumorDataset\n",
    "from models.vgg_custom import VGGCustom\n",
    "import copy\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "EPOCHS, BATCH_SIZE, LR = 50, 16, 3e-4  # Batch size eski haline döndürüldü\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ACCUMULATION_STEPS = 2  # Gradient accumulation steps\n",
    "\n",
    "def build_dataloaders():\n",
    "    cpu_pre = T.Compose([T.ToImage(),\n",
    "                         T.ToDtype(torch.float32, scale=True)])\n",
    "    train_ds = CustomTumorDataset(\"preprocessed_data/train\", transform=cpu_pre)\n",
    "    val_ds   = CustomTumorDataset(\"preprocessed_data/val\",   transform=cpu_pre)\n",
    "    \n",
    "    print(\"[LOG] Eğitim veri kümesinin sinif listesi:\", train_ds.classes)\n",
    "    print(\"[LOG] valid veri kümesinin sinif listesi:\", val_ds.classes)\n",
    "    train_labels = [label for _, label in train_ds.samples]\n",
    "    val_labels   = [label for _, label in val_ds.samples]\n",
    "\n",
    "    print(\"[LOG] train label dağılımı:\", Counter(train_labels))\n",
    "    print(\"[LOG] valid label dağılımı:\", Counter(val_labels))\n",
    "    \n",
    "    # DataLoader optimizasyonları\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            num_workers=4,  # Worker sayısı eski haline döndürüldü\n",
    "                            pin_memory=True, \n",
    "                            persistent_workers=True,\n",
    "                            prefetch_factor=2)  # Prefetch eski haline döndürüldü\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE*2, shuffle=False,\n",
    "                            num_workers=4,  # Worker sayısı eski haline döndürüldü\n",
    "                            pin_memory=True,\n",
    "                            persistent_workers=True,\n",
    "                            prefetch_factor=2)  # Prefetch eski haline döndürüldü\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def run_epoch(model, loader, criterion, optim=None, gpu_aug=None, scaler=None):\n",
    "    train = optim is not None\n",
    "    model.train() if train else model.eval()\n",
    "    tot_loss = correct = total = 0\n",
    "\n",
    "    iterator = tqdm(loader, leave=True, ascii=True, dynamic_ncols=True) if train else loader\n",
    "\n",
    "    for i, (X, y) in enumerate(iterator):\n",
    "        X, y = X.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)\n",
    "        if train:\n",
    "            X = gpu_aug(X)\n",
    "        \n",
    "        with torch.set_grad_enabled(train):\n",
    "            with autocast('cuda', enabled=True):\n",
    "                out  = model(X)\n",
    "                loss = criterion(out, y)\n",
    "                if train:\n",
    "                    loss = loss / ACCUMULATION_STEPS\n",
    "            \n",
    "            if train:\n",
    "                scaler.scale(loss).backward()\n",
    "                if (i + 1) % ACCUMULATION_STEPS == 0:\n",
    "                    scaler.unscale_(optim)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    scaler.step(optim)\n",
    "                    scaler.update()\n",
    "                    optim.zero_grad(set_to_none=True)\n",
    "\n",
    "        tot_loss += loss.item() * y.size(0) * (ACCUMULATION_STEPS if train else 1)\n",
    "        correct  += (out.argmax(1) == y).sum().item()\n",
    "        total    += y.size(0)\n",
    "\n",
    "    return tot_loss / total, correct / total\n",
    "\n",
    "def train():\n",
    "    # CUDA optimizasyonları\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    train_loader, val_loader = build_dataloaders()\n",
    "\n",
    "    # Class weights hesapla\n",
    "    train_labels = [label for _, label in train_loader.dataset.samples]\n",
    "    class_sample_count = torch.tensor([(torch.tensor(train_labels) == t).sum() for t in torch.unique(torch.tensor(train_labels))], dtype=torch.float32)\n",
    "    class_weights = 1. / class_sample_count\n",
    "    class_weights = class_weights / class_weights.sum() * len(class_sample_count)  # normalize et\n",
    "    class_weights = class_weights.to(DEVICE)\n",
    "\n",
    "    model = VGGCustom(num_classes=3).to(DEVICE)\n",
    "    optim = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=2)\n",
    "    scaler = GradScaler('cuda')\n",
    "    \n",
    "    # Learning rate warmup ve scheduler\n",
    "    num_warmup_steps = len(train_loader) * 2  # 2 epoch warmup\n",
    "    num_training_steps = len(train_loader) * EPOCHS\n",
    "    \n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return 0.5 * (1.0 + torch.cos(torch.pi * float(current_step - num_warmup_steps) / float(num_training_steps - num_warmup_steps)))\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda)\n",
    "    \n",
    "    gpu_aug = T.Identity()\n",
    "\n",
    "    # Cache boyutunu sınırla\n",
    "    max_cache_size = 5  # 5 checkpoint\n",
    "    cache = []\n",
    "    stuck_count = 0\n",
    "    window = 5  # 5 window\n",
    "    val_loss_hist = []\n",
    "    val_acc_hist = []\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    best_val_acc = 0\n",
    "    patience = 5\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for ep in range(1, EPOCHS + 1):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        tr_l, tr_a = run_epoch(model, train_loader, criterion,\n",
    "                               optim=optim, gpu_aug=gpu_aug, scaler=scaler)\n",
    "        vl_l, vl_a = run_epoch(model, val_loader, criterion)\n",
    "\n",
    "        # Cache güncelle (boyut kontrolü ile)\n",
    "        cache.append({\n",
    "            \"model\": copy.deepcopy(model.state_dict()),\n",
    "            \"optim\": copy.deepcopy(optim.state_dict()),\n",
    "            \"train_loss\": tr_l,\n",
    "            \"val_loss\": vl_l,\n",
    "            \"train_acc\": tr_a,\n",
    "            \"val_acc\": vl_a\n",
    "        })\n",
    "        if len(cache) > max_cache_size:\n",
    "            cache.pop(0)\n",
    "\n",
    "        # Bellek temizliği\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        train_loss_hist.append(tr_l)\n",
    "        val_loss_hist.append(vl_l)\n",
    "        train_acc_hist.append(tr_a)\n",
    "        val_acc_hist.append(vl_a)\n",
    "        if len(val_loss_hist) > window:\n",
    "            val_loss_hist.pop(0)\n",
    "            train_loss_hist.pop(0)\n",
    "            val_acc_hist.pop(0)\n",
    "            train_acc_hist.pop(0)\n",
    "\n",
    "        # --- Gelişmiş Kriterler ---\n",
    "        overfit = False\n",
    "        underfit = False\n",
    "        \n",
    "        # 1. Acc farkı ve eğilim analizi\n",
    "        if len(val_acc_hist) >= 3:\n",
    "            acc_trend = sum(val_acc_hist[-3:]) / 3 - sum(val_acc_hist[-6:-3]) / 3\n",
    "            if abs(tr_a - vl_a) > 0.15 and tr_a > vl_a and acc_trend < 0:\n",
    "                overfit = True\n",
    "            if tr_a < 0.6 and vl_a < 0.6 and acc_trend < 0:\n",
    "                underfit = True\n",
    "\n",
    "        # 2. Loss farkı ve eğilim analizi\n",
    "        if len(val_loss_hist) >= 3:\n",
    "            loss_trend = sum(val_loss_hist[-3:]) / 3 - sum(val_loss_hist[-6:-3]) / 3\n",
    "            if abs(vl_l - tr_l) > 0.2 and vl_l > tr_l and loss_trend > 0:\n",
    "                overfit = True\n",
    "            if tr_l > 1.2 and vl_l > 1.2 and loss_trend > 0:\n",
    "                underfit = True\n",
    "\n",
    "        # --- Dinamik LR ve rollback ---\n",
    "        if overfit:\n",
    "            for g in optim.param_groups:\n",
    "                g['lr'] *= 0.5\n",
    "            stuck_count += 1\n",
    "            print(f\"[CACHE] Overfitting tespit edildi! LR yarıya indirildi. (Ep{ep})\")\n",
    "        elif underfit:\n",
    "            for g in optim.param_groups:\n",
    "                g['lr'] *= 1.2\n",
    "            stuck_count += 1\n",
    "            print(f\"[CACHE] Underfitting tespit edildi! LR artırıldı. (Ep{ep})\")\n",
    "        else:\n",
    "            stuck_count = 0\n",
    "\n",
    "        if stuck_count >= 2 and len(cache) >= 3:  # 2 önceki checkpoint'e dön\n",
    "            model.load_state_dict(cache[-3][\"model\"])\n",
    "            optim.load_state_dict(cache[-3][\"optim\"])\n",
    "            print(f\"[CACHE] 2 kez fitting problemi! 2 önceki ağırlıklara dönüldü. (Ep{ep})\")\n",
    "            stuck_count = 0\n",
    "            continue\n",
    "\n",
    "        # Early stopping kontrolü\n",
    "        if vl_a > best_val_acc:\n",
    "            best_val_acc = vl_a\n",
    "            no_improve_epochs = 0\n",
    "            torch.save(model.state_dict(), \"models/best_vgg_custom.pt\")\n",
    "            print(f\"[✓] Yeni en iyi model kaydedildi! Doğruluk: {vl_a:.4f}\")\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(f\"[!] Early stopping: {patience} epoch boyunca iyileşme yok.\")\n",
    "            break\n",
    "\n",
    "        # Progressive block açma\n",
    "        opened = sum([any(p.requires_grad for p in blk.parameters()) for blk in model.blocks])\n",
    "        if opened == 2:\n",
    "            block_open_threshold = 7  # 2 blok açıkken 3. blok için\n",
    "        else:\n",
    "            block_open_threshold = 4  # Diğer bloklar için\n",
    "        if no_improve_epochs >= block_open_threshold and hasattr(model, 'freeze_blocks_until') and hasattr(model, 'blocks'):\n",
    "            if opened < len(model.blocks):\n",
    "                model.freeze_blocks_until(opened)\n",
    "                optim = torch.optim.AdamW(\n",
    "                    filter(lambda p: p.requires_grad, model.parameters()), lr=optim.param_groups[0]['lr'])\n",
    "                print(f\"[+] {ep}. epoch → Block-{opened+1} açıldı\")\n",
    "                no_improve_epochs = 0\n",
    "\n",
    "        scheduler.step()\n",
    "        current_lr = optim.param_groups[0]['lr']\n",
    "        print(f\"[Ep{ep:02d}] time={time.time()-t0:.1f}s | \"\n",
    "              f\"train_acc={tr_a:.4f} | val_acc={vl_a:.4f} | \"\n",
    "              f\"train_loss={tr_l:.4f} | val_loss={vl_l:.4f} | \"\n",
    "              f\"lr={current_lr:.2e} | no_imp={no_improve_epochs} | \"\n",
    "              f\"{time.time()-t0:.1f}s| \"\n",
    "              f\"block : {sum([any(p.requires_grad for p in blk.parameters()) for blk in model.blocks])}\")\n",
    "\n",
    "        if vl_a >= 0.955:\n",
    "            print(f\"[✓] %{vl_a:.4f} doğruluk – eğitim bitti.\")\n",
    "            break\n",
    "\n",
    "        # Log grafiklerini oluştur ve kaydet\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_acc_hist, label='Train Acc')\n",
    "        plt.plot(val_acc_hist, label='Val Acc')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Accuracy over epochs')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_loss_hist, label='Train Loss')\n",
    "        plt.plot(val_loss_hist, label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Loss over epochs')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'logs/epoch_{ep:02d}_logs.png')\n",
    "        plt.close()\n",
    "\n",
    "def freeze_support_for_win():\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    freeze_support_for_win()\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train()  # Eğitim başlatılır, log görselleri logs/ klasörüne kaydedilir\n",
    "\n",
    "# Son epoch log görselini göster\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "log_imgs = sorted(glob.glob('logs/epoch_*_logs.png'))\n",
    "if log_imgs:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(log_imgs[-1]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

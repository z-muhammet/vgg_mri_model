
# BrainMRIModel

Bu proje, beyin MRI gÃ¶rÃ¼ntÃ¼lerinden tÃ¼mÃ¶r tespiti ve sÄ±nÄ±flandÄ±rmasÄ± iÃ§in derin Ã¶ÄŸrenme tabanlÄ± bir model geliÅŸtirmeyi amaÃ§lamaktadÄ±r. Proje, PyTorch Ã§erÃ§evesini kullanarak Ã¶zel bir EvriÅŸimsel Sinir AÄŸÄ± (CNN) mimarisi eÄŸitir ve model performansÄ±nÄ± artÄ±rmak iÃ§in Ã§eÅŸitli geliÅŸmiÅŸ eÄŸitim stratejileri ve veri artÄ±rma teknikleri kullanÄ±r.

![FCwe9UJ.md.png](https://iili.io/FCwe9UJ.md.png)

## KullanÄ±lan Teknolojiler ve KÃ¼tÃ¼phaneler

*   **Derin Ã–ÄŸrenme Ã‡erÃ§evesi:** PyTorch
*   **Veri Ä°ÅŸleme:** NumPy, PIL (Python Imaging Library), Albumentations
*   **GÃ¶rselleÅŸtirme:** Matplotlib
*   **Optimizasyon:** `torch.optim`
*   **GeliÅŸtirme Dili:** Python

## Model Mimarisi (models/basic_cnn_model.py)

Projenin kalbinde, Ã¶zel olarak tasarlanmÄ±ÅŸ `BasicCNNModel` adÄ±nda VGG benzeri bir EvriÅŸimsel Sinir AÄŸÄ± (CNN) bulunmaktadÄ±r.

*   **Temel Katmanlar:** `nn.Conv2d`, `nn.GroupNorm`, `nn.SiLU`, `nn.Identity`, `nn.Dropout2d`, `nn.AdaptiveAvgPool2d`, `nn.BatchNorm1d`, `nn.Mish`, `nn.Linear`.
*   **`TrainOnlyNoise`:** Sadece eÄŸitim sÄ±rasÄ±nda girdi verisine gÃ¼rÃ¼ltÃ¼ ekleyen Ã¶zel bir katman.
*   **`ConvBlock`:** Her biri evriÅŸim, 32 gruplu grup normalizasyonu ve `SiLU` aktivasyonu iÃ§eren temel yapÄ± taÅŸlarÄ±. Bu bloklar, bir `Dropout2d` ve `TrainOnlyNoise` katmanÄ± da iÃ§erir. KalÄ±ntÄ± baÄŸlantÄ±lar (shortcut connections) bu blok iÃ§inde uygulanmamÄ±ÅŸtÄ±r.
*   **Blok YapÄ±sÄ±:** Model, ayrÄ± ayrÄ± dondurulabilen ve aÃ§Ä±labilen Ã¼Ã§ ana bloktan oluÅŸur. Bu, aÅŸamalÄ± Ã¶ÄŸrenme stratejisini mÃ¼mkÃ¼n kÄ±lar.
*   **Dinamik AdaptÃ¶rler:** Son aÃ§Ä±lan bloÄŸun Ã§Ä±ktÄ±sÄ±nÄ± sÄ±nÄ±flandÄ±rma katmanÄ±na uygun hale getiren adaptÃ¶r katmanlarÄ±.
*   **AÄŸÄ±rlÄ±k BaÅŸlatma:** Kaiming Normal (He normal) ve sabit baÅŸlatma teknikleri kullanÄ±lmÄ±ÅŸtÄ±r.
*   **AÅŸamalÄ± Ã–ÄŸrenme (Progressive Learning):** `freeze_blocks_until` metodu ile modelin katmanlarÄ± kademeli olarak eÄŸitilir. BaÅŸlangÄ±Ã§ta yalnÄ±zca ilk blok (Blok 1) eÄŸitilebilir durumdadÄ±r. EÄŸitim sÄ±rasÄ±nda, belirli koÅŸullar altÄ±nda (ÅŸu anki uygulamada Blok 2, 15. epokta aÃ§Ä±lmaya zorlanÄ±r; Blok 3'Ã¼n aÃ§Ä±lmasÄ± ise engellenir) diÄŸer bloklar dondurulmuÅŸ durumdan Ã§Ä±karÄ±lÄ±r.

    *   **Blok DetaylarÄ±:**
        *   **Blok 1:** GiriÅŸ katmanlarÄ±nÄ± (Ã¶rn. 3 kanal) alÄ±r ve 64 Ã§Ä±kÄ±ÅŸ kanalÄ± Ã¼retir. Ä°ki adet `ConvBlock` katmanÄ± ve bir `Dropout2d` katmanÄ± iÃ§erir. Ä°kinci `ConvBlock` downsampling (`stride=2`) yapar.
        *   **Blok 2:** 64 giriÅŸ kanalÄ± ile baÅŸlar ve 512 Ã§Ä±kÄ±ÅŸ kanalÄ± Ã¼retir. ÃœÃ§ adet `ConvBlock` katmanÄ± ve bir `Dropout2d` katmanÄ± iÃ§erir. Son `ConvBlock` downsampling (`stride=2`) yapar ve `dilation=2` kullanÄ±r.
        *   **Blok 3:** 512 giriÅŸ kanalÄ± ile baÅŸlar ve 256 Ã§Ä±kÄ±ÅŸ kanalÄ± Ã¼retir. ÃœÃ§ adet `ConvBlock` katmanÄ± ve bir `Dropout2d` katmanÄ± iÃ§erir. Son `ConvBlock` downsampling (`stride=2`) yapar.
*   **Ã‡Ä±kÄ±ÅŸ Dense KatmanlarÄ±:**
    *   **Blok 1 Ã‡Ä±kÄ±ÅŸÄ±:** 64 kanal Ã§Ä±kÄ±ÅŸÄ±, 128 nÃ¶ronlu bir dense katmanÄ±na baÄŸlanÄ±r.
    *   **Blok 2 Ã‡Ä±kÄ±ÅŸÄ±:** 512 kanal Ã§Ä±kÄ±ÅŸÄ± doÄŸrudan son dense katmanÄ±na baÄŸlanÄ±r.
    *   **Blok 3 Ã‡Ä±kÄ±ÅŸÄ±:** 256 kanal Ã§Ä±kÄ±ÅŸÄ±, 128 nÃ¶ronlu bir dense katmanÄ±na baÄŸlanÄ±r.
    *   **Son Dense KatmanÄ±:** TÃ¼m bloklarÄ±n dense katmanlarÄ± birleÅŸtirilerek 512 nÃ¶ronlu bir ara katmana baÄŸlanÄ±r ve son olarak 3 sÄ±nÄ±flÄ± Ã§Ä±kÄ±ÅŸ katmanÄ±na (softmax) baÄŸlanÄ±r.

## Blok KullanÄ±mÄ± ve Katman SayÄ±sÄ±

Modelin eÄŸitimi, hangi blokta sonlandÄ±ÄŸÄ±na baÄŸlÄ± olarak farklÄ± sayÄ±da katman kullanÄ±r:

*   **Blok 1 ile SonlanÄ±rsa:**
    *   2 adet `ConvBlock` (her biri 4 katman: Conv2d, GroupNorm, SiLU, Dropout2d)
    *   1 adet Dropout2d (0.1)
    *   1 adet AdaptiveAvgPool2d
    *   1 adet BatchNorm1d
    *   1 adet Linear (64->512) adaptÃ¶r
    *   1 adet Linear (512->3) sÄ±nÄ±flandÄ±rÄ±cÄ±
    *   Toplam: 2 adet conv2d - 2 adet dense

*   **Blok 2 ile SonlanÄ±rsa:**
    *   Blok 1'in tÃ¼m katmanlarÄ±
    *   3 adet `ConvBlock` (her biri 4 katman: Conv2d, GroupNorm, SiLU, Dropout2d)
    *   1 adet Dropout2d (0.2)
    *   1 adet BatchNorm1d
    *   1 adet Identity adaptÃ¶r (512->512)
    *   1 adet Linear (512->3) sÄ±nÄ±flandÄ±rÄ±cÄ±
    *   Toplam: ~ 2 + 2 adet conv2d 1 dense 

*   **Blok 3 ile SonlanÄ±rsa: (AÃ§Ä±lmasÄ± ÅŸuanki TasarÄ±m ile izin verilmiyor)**
    *   Blok 1 ve 2'nin tÃ¼m katmanlarÄ±
    *   3 adet `ConvBlock` (her biri 4 katman: Conv2d, GroupNorm, SiLU, Dropout2d)
    *   1 adet Dropout2d (0.3)
    *   1 adet AdaptiveAvgPool2d
    *   1 adet BatchNorm1d
    *   1 adet Linear (256->512) adaptÃ¶r
    *   1 adet Linear (512->3) sÄ±nÄ±flandÄ±rÄ±cÄ±
    *   Toplam: ~2 + 2 + 3 adet conv2d 1 adet pooling 2 adet dense

Not: Her `ConvBlock` iÃ§indeki shortcut connection'lar da hesaba katÄ±ldÄ±ÄŸÄ±nda, gerÃ§ek katman sayÄ±sÄ± biraz daha yÃ¼ksek olabilir. AyrÄ±ca, eÄŸitim sÄ±rasÄ±nda bazÄ± katmanlar dondurulmuÅŸ (frozen) olabilir, bu durumda aktif katman sayÄ±sÄ± azalÄ±r.

## EÄŸitim ProsedÃ¼rleri ve AlgoritmalarÄ± (models/train.py)

Modelin eÄŸitimi iÃ§in Ã§eÅŸitli modern teknikler ve algoritmalar kullanÄ±lmÄ±ÅŸtÄ±r:

*   **Optimizasyon:** `torch.optim.AdamW` optimizer, `5e-4` aÄŸÄ±rlÄ±k azaltma (`weight_decay`) ile kullanÄ±lÄ±r. Bu, modelin aÅŸÄ±rÄ± Ã¶ÄŸrenmesini engellemeye yardÄ±mcÄ± olur.
*   **KayÄ±p Fonksiyonu:** `nn.CrossEntropyLoss` kullanÄ±lÄ±r. SÄ±nÄ±f dengesizliÄŸini gidermek amacÄ±yla `get_class_balanced_weights` fonksiyonu tarafÄ±ndan hesaplanan sÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± (`class_weights`) ile birlikte kullanÄ±lÄ±r. Bu aÄŸÄ±rlÄ±klar, her 10 epokta bir normalize edilir ve eÄŸitim-doÄŸrulama doÄŸruluÄŸu arasÄ±ndaki farka gÃ¶re dinamik olarak ayarlanÄ±r (ClassPenalty mekanizmasÄ±).
*   **Ã–ÄŸrenme OranÄ± Ã‡izelgeleyiciler (LR Schedulers):** Esnek ve dinamik bir Ã¶ÄŸrenme oranÄ± stratejisi uygulanÄ±r. BaÅŸlangÄ±Ã§ Ã¶ÄŸrenme oranÄ± `1e-2`'dir.
    *   **`OneCycleLR`:** Ä°lk `COSINE_START_EPOCH` (varsayÄ±lan 20) epoka kadar maksimum Ã¶ÄŸrenme oranÄ±na ulaÅŸÄ±r ve sonra kosinÃ¼s anneal stratejisi ile azaltÄ±r. Bu, hÄ±zlÄ± yakÄ±nsama ve daha iyi genelleme saÄŸlar.
    *   **`CosineAnnealingLR`:** `COSINE_START_EPOCH`'tan `SWA_START_EPOCH - 1`'e kadar (varsayÄ±lan 20-60 arasÄ±) Ã¶ÄŸrenme oranÄ±nÄ± kosinÃ¼s dalgasÄ± ÅŸeklinde `1e-5` minimum deÄŸere kadar azaltÄ±r.
    *   **`LinearLR` (SWA FazÄ± iÃ§in):** `SWA_START_EPOCH`'tan (`NUM_EPOCHS + 1`, yani varsayÄ±lan 61. epoktan itibaren) eÄŸitim sonuna kadar sabit bir Ã¶ÄŸrenme oranÄ± (`SWA_LR = 5e-4`) korur. Bu, SWA modelinin stabil bir ÅŸekilde yakÄ±nsamasÄ±na yardÄ±mcÄ± olur.
    *   **`SequentialLR`:** YukarÄ±daki Ã§izelgeleyicileri belirli mihenk taÅŸlarÄ±nda (`milestones`) sÄ±rayla etkinleÅŸtirir.
    *   Alternatif olarak, doÄŸrulama kaybÄ± plato yaptÄ±ÄŸÄ±nda Ã¶ÄŸrenme oranÄ±nÄ± `0.2` faktÃ¶rÃ¼ ile azaltan `ReduceLROnPlateau` Ã§izelgeleyici (`patience=3`, `min_lr=1e-7`) de kullanÄ±labilir.
*   **Mixup:** Girdi gÃ¶rÃ¼ntÃ¼leri ve etiketleri lineer olarak karÄ±ÅŸtÄ±rÄ±larak veri Ã§eÅŸitliliÄŸini artÄ±ran bir veri artÄ±rma tekniÄŸidir. `mixup_data` fonksiyonu tarafÄ±ndan `alpha=0.2` ile uygulanÄ±r. Mixup alfa deÄŸeri eÄŸitimin erken aÅŸamalarÄ±nda (0. epoktan 15. epoka kadar) lineer olarak `0.0`'a dÃ¼ÅŸÃ¼rÃ¼lÃ¼r, bu da modelin baÅŸlangÄ±Ã§ta daha fazla Ã§eÅŸitlilikle eÄŸitilmesini, sonrasÄ±nda ise gerÃ§ek verilere odaklanmasÄ±nÄ± saÄŸlar.
*   **Dinamik DÃ¼zenlileÅŸtirme (`DynamicRegularization`):** Modelin eÄŸitim performansÄ±na (aÅŸÄ±rÄ± Ã¶ÄŸrenme veya az Ã¶ÄŸrenme) gÃ¶re dropout oranlarÄ±nÄ± dinamik olarak ayarlayan bir mekanizmadÄ±r. AÅŸÄ±rÄ± Ã¶ÄŸrenme belirtileri (`tr_acc - val_acc > OVERFIT_THRESHOLD`) gÃ¶rÃ¼ldÃ¼ÄŸÃ¼nde dropout faktÃ¶rÃ¼nÃ¼ artÄ±rÄ±r, az Ã¶ÄŸrenme (`val_acc < UNDERFIT_THRESHOLD`) durumunda ise azaltÄ±r.
*   **SÄ±caklÄ±k Ã–lÃ§eklendirme (`TemperatureScaler`):** Modelin tahmin gÃ¼venilirliklerini kalibre etmek iÃ§in kullanÄ±lan Ã¶ÄŸrenilebilir bir sÄ±caklÄ±k parametresi (`temperature`) iÃ§erir. EÄŸitim sonunda SWA modeli Ã¼zerinde kalibre edilir.
*   **Geri Alma MekanizmasÄ± (Rollback):** DoÄŸrulama doÄŸruluÄŸunda belirgin bir dÃ¼ÅŸÃ¼ÅŸ veya kayÄ±pta artÄ±ÅŸ olduÄŸunda (`acc_drop >= ROLLBACK_ACC_THRESHOLD` veya `loss_rise >= ROLLBACK_LOSS_THRESHOLD`), modelin daha Ã¶nceki en iyi aÄŸÄ±rlÄ±klarÄ±na geri dÃ¶nmesini saÄŸlar. Bu, istenmeyen performans dÃ¼ÅŸÃ¼ÅŸlerinin Ã¶nÃ¼ne geÃ§mek iÃ§in Ã¶nemli bir stratejidir. Maksimum 10 geri alma iÅŸlemi (`MAX_TOTAL_ROLLBACKS`) ve bir soÄŸuma sÃ¼resi (`ROLLBACK_COOLDOWN = 5` epok) iÃ§erir.
*   **SÄ±nÄ±f CezasÄ± (ClassPenalty):** EÄŸitim ve doÄŸrulama doÄŸruluÄŸu arasÄ±ndaki sÄ±nÄ±f bazlÄ± fark (`per_class_gap`) belirli eÅŸikler (`PENALTY_GAP_LOW`, `PENALTY_GAP_HIGH`) iÃ§inde olduÄŸunda ve 30. epokdan sonra etkinleÅŸir. Bu durumda, daha kÃ¶tÃ¼ performans gÃ¶steren sÄ±nÄ±flarÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± artÄ±rarak (`1.03` faktÃ¶rle) ve daha iyi performans gÃ¶steren sÄ±nÄ±flarÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± azaltarak (`0.97` faktÃ¶rle) sÄ±nÄ±f dengesizliÄŸini eÄŸitim sÃ¼resince dinamik olarak dÃ¼zenler. AyrÄ±ca, 40, 50 ve 55. epoklarda '1_menin' sÄ±nÄ±fÄ± iÃ§in Ã¶zel aÄŸÄ±rlÄ±k artÄ±ÅŸlarÄ± uygulanÄ±r.
*   **Erken Durdurma:** `EARLY_STOPPING_PATIENCE` (varsayÄ±lan 18) epok boyunca doÄŸrulama doÄŸruluÄŸunda iyileÅŸme olmazsa eÄŸitim durdurulur. En iyi model aÄŸÄ±rlÄ±klarÄ± bu sÃ¼re zarfÄ±nda kaydedilir.
*   **Rastgele AÄŸÄ±rlÄ±k OrtalamasÄ± (Stochastic Weight Averaging - SWA):** `SWA_START_EPOCH`'tan itibaren (`NUM_EPOCHS + 1`, yani varsayÄ±lan 61. epok) `AveragedModel` kullanÄ±larak model aÄŸÄ±rlÄ±klarÄ±nÄ±n ortalamasÄ± alÄ±narak genelleme yeteneÄŸi artÄ±rÄ±lÄ±r. EÄŸitim sonunda `update_bn` ile BatchNorm katmanlarÄ± gÃ¼ncellenir ve SWA modeli ayrÄ± bir checkpoint olarak kaydedilir.
*   **AÅŸamalÄ± Ã–ÄŸrenme (Progressive Learning):** `models/basic_cnn_model.py`'de tanÄ±mlanan `freeze_blocks_until` metodu ile modelin katmanlarÄ± kademeli olarak eÄŸitilir. EÄŸitim sÄ±rasÄ±nda, belirli koÅŸullar altÄ±nda (ÅŸu anki uygulamada Blok 2, 15. epokta aÃ§Ä±lmaya zorlanÄ±r; Blok 3'Ã¼n aÃ§Ä±lmasÄ± ise engellenir) diÄŸer bloklar dondurulmuÅŸ durumdan Ã§Ä±karÄ±lÄ±r.

## GPU Performans OptimizasyonlarÄ±

Proje, GPU performansÄ±nÄ± en Ã¼st dÃ¼zeye Ã§Ä±karmak ve eÄŸitim sÃ¼recini hÄ±zlandÄ±rmak iÃ§in Ã§eÅŸitli modern teknolojiler ve teknikler kullanÄ±r:

*   **Otomatik KarÄ±ÅŸÄ±k Hassasiyet (Automatic Mixed Precision - AMP):** `torch.amp.autocast` ve `torch.cuda.amp.GradScaler` kullanarak hem hÄ±z hem de bellek verimliliÄŸi iÃ§in Float32 ve Float16 veri tiplerini dinamik olarak karÄ±ÅŸtÄ±rÄ±r. Uyumlu GPU'larda (Tensor Core gibi) daha hÄ±zlÄ± matematik iÅŸlemleri saÄŸlar ve bellek kullanÄ±mÄ±nÄ± optimize eder. `amp_enabled` bayraÄŸÄ± ile kontrol edilir ve yalnÄ±zca CUDA cihazÄ± mevcut ve BF16 destekliyorsa etkinleÅŸtirilir.
*   **Gradiyent Biriktirme (Gradient Accumulation):** `GRADIENT_ACCUMULATION_STEPS` (varsayÄ±lan 4) ile belirtilen adÄ±mlarla gradyanlarÄ± biriktirerek daha bÃ¼yÃ¼k bir "efektif batch boyutu" simÃ¼le eder. Bu, GPU belleÄŸi kÄ±sÄ±tlÄ±yken bile bÃ¼yÃ¼k batch boyutlarÄ±nÄ±n faydalarÄ±ndan yararlanmayÄ± saÄŸlar. `loss / GRADIENT_ACCUMULATION_STEPS).backward()` ile uygulanÄ±r.
*   **`DataLoader` OptimizasyonlarÄ±:**
    *   **`num_workers`:** Veri yÃ¼klemesini ayrÄ± alt iÅŸlemlere daÄŸÄ±tarak CPU'nun veri hazÄ±rlÄ±ÄŸÄ±na, GPU'nun ise model eÄŸitimine odaklanabilmesini saÄŸlar. Windows iÅŸletim sistemleri iÃ§in `0` olarak ayarlanÄ±r ve `persistent_workers` devre dÄ±ÅŸÄ± bÄ±rakÄ±lÄ±r (`freeze_support_for_win` fonksiyonu ile).
    *   **`pin_memory=True`:** Verinin GPU'ya kopyalanmasÄ±nÄ± hÄ±zlandÄ±rmak iÃ§in CPU belleÄŸinde sabitlenmiÅŸ bir alana yÃ¼klenmesini saÄŸlar.
    *   **`persistent_workers=True`:** `DataLoader` alt iÅŸlemlerinin epochlar arasÄ±nda yeniden baÅŸlatÄ±lmasÄ±nÄ± engelleyerek ek yÃ¼kÃ¼ azaltÄ±r ve veri yÃ¼kleme sÃ¼resini kÄ±saltÄ±r. (Windows iÃ§in kÄ±sÄ±tlamalar nedeniyle otomatik olarak `False` olarak ayarlanÄ±r).
    *   **`drop_last=True`:** Son batch'in tam olmamasÄ± durumunda atÄ±lmasÄ±nÄ± saÄŸlar, bu da model boyutlarÄ± veya batch norm gibi bazÄ± mimariler iÃ§in daha kararlÄ± eÄŸitim saÄŸlayabilir.
*   **GPU Bellek YÃ¶netimi:**
    *   **`torch.cuda.empty_cache()`:** GPU Ã¼zerindeki Ã¶nbelleÄŸi boÅŸaltarak bellek fragmentasyonunu ve gereksiz bellek kullanÄ±mÄ±nÄ± azaltÄ±r. Her epoch sonunda Ã§aÄŸrÄ±lÄ±r.
    *   **`gc.collect()`:** Python'Ä±n Ã§Ã¶p toplayÄ±cÄ±sÄ±nÄ± manuel olarak tetikleyerek GPU belleÄŸinin daha verimli serbest bÄ±rakÄ±lmasÄ±na yardÄ±mcÄ± olur. Her epoch sonunda Ã§aÄŸrÄ±lÄ±r.
    *   **`set_to_none=True` ile `optim.zero_grad()`:** Gradyan tensÃ¶rlerini doÄŸrudan sÄ±fÄ±rlamak yerine `None` olarak ayarlayarak bellek tahsisini optimize eder.
*   **`ConvBlock` Ä°yileÅŸtirmeleri (DolaylÄ± Etki):**
    *   **`GroupNorm`:** Daha kÃ¼Ã§Ã¼k batch boyutlarÄ±nda stabilite saÄŸlar ve bazÄ± GPU mimarilerinde performansÄ± artÄ±rabilir.
    *   **`kernel_size=3`:** Daha az hesaplama gerektirir ve daha derin aÄŸlarÄ±n daha verimli Ã§alÄ±ÅŸmasÄ±na olanak tanÄ±r.
    *   **`SiLU()` aktivasyon fonksiyonu:** DiÄŸer bazÄ± aktivasyonlara gÃ¶re daha dÃ¼ÅŸÃ¼k hesaplama maliyetine sahip olabilir.
    *   **`nn.Dropout2d` (Spatial Dropout):** Uzamsal baÄŸÄ±ntÄ±larÄ± koruyarak daha etkili bir dÃ¼zenlileÅŸtirme ve genelleme saÄŸlar, bu da daha az epokta iyi sonuÃ§lar elde etmeye yardÄ±mcÄ± olabilir.

## Veri YÃ¼kleme ve Ã–n Ä°ÅŸleme (dataset/custom_dataset.py)

Veri seti iÅŸlemleri iÃ§in Ã¶zel bir PyTorch `Dataset` sÄ±nÄ±fÄ± (`CustomTumorDataset`) kullanÄ±lmÄ±ÅŸtÄ±r:

*   **`CustomTumorDataset`:** `.npy` formatÄ±ndaki Ã¶n iÅŸlenmiÅŸ gÃ¶rÃ¼ntÃ¼lerden veri yÃ¼kler. Bu, veri okuma hÄ±zÄ±nÄ± artÄ±rÄ±r.
*   **GÃ¶rÃ¼ntÃ¼ ArtÄ±rma ve DÃ¶nÃ¼ÅŸÃ¼mler:** `Albumentations` kÃ¼tÃ¼phanesi ile Ã§eÅŸitli rastgele dÃ¶nÃ¼ÅŸÃ¼mler uygulanÄ±r. Bu dÃ¶nÃ¼ÅŸÃ¼mler eÄŸitim epoklarÄ±na gÃ¶re dinamik olarak ayarlanÄ±r (`_get_current_augmenter` metodu):
    *   **Erken EÄŸitim FazÄ± (0-10 Epok):** Modelin daha Ã§eÅŸitli verilere maruz kalmasÄ± iÃ§in daha yÃ¼ksek ÅŸiddetli artÄ±rmalar uygulanÄ±r. Bu aÅŸama, modelin ilk Ã¶ÄŸrenme eÄŸrisini hÄ±zlandÄ±rmasÄ±na yardÄ±mcÄ± olur.
        *   `A.Rotate(limit=5, p=0.3)`
        *   `A.RandomRotate90(p=0.1)`
        *   `A.OneOf([A.HorizontalFlip(p=1.0), A.VerticalFlip(p=1.0)], p=0.3)`
        *   `A.Affine(translate_percent={'x': 0.02, 'y': 0.02}, scale={'x': (0.96, 1.04), 'y': (0.96, 1.04)}, p=0.3)`
        *   `A.RandomBrightnessContrast(brightness_limit=0.08, contrast_limit=0.08, p=0.3)`
        *   `A.GaussNoise(std_range=(0.005, 0.015), mean_range=(0.0, 0.0), p=0.1)`
    *   **Orta EÄŸitim FazÄ± (10-40 Epok):** ArtÄ±rmalarÄ±n ÅŸiddeti ve olasÄ±lÄ±klarÄ± azaltÄ±larak modelin daha oturmuÅŸ Ã¶ÄŸrenmesine olanak tanÄ±nÄ±r. Bu, modelin daha ince detaylarÄ± Ã¶ÄŸrenmesine yardÄ±mcÄ± olur.
        *   `A.Rotate(limit=3, p=0.1)`
        *   `A.RandomRotate90(p=0.05)`
        *   `A.OneOf([A.HorizontalFlip(p=1.0), A.VerticalFlip(p=1.0)], p=0.1)`
        *   `A.Affine(translate_percent={'x': 0.005, 'y': 0.005}, scale={'x': (0.99, 1.01), 'y': (0.99, 1.01)}, p=0.1)`
        *   `A.RandomBrightnessContrast(brightness_limit=0.02, contrast_limit=0.02, p=0.1)`
        *   `A.GaussNoise(std_range=(0.003, 0.008), mean_range=(0.0, 0.0), p=0.05)`
    *   **Son EÄŸitim FazÄ± (40+ Epok):** Minimal artÄ±rmalar uygulanÄ±r, genellikle sadece temel dÃ¶nÃ¼ÅŸÃ¼mlerle modelin ince ayar yapmasÄ±na izin verilir. Bu aÅŸama, modelin genelleme yeteneÄŸini optimize etmeye odaklanÄ±r.
        *   `A.HorizontalFlip(p=1.0)`
    *   **Sabit DÃ¶nÃ¼ÅŸÃ¼mler:** TÃ¼m artÄ±rma aÅŸamalarÄ±ndan sonra uygulanan sabit dÃ¶nÃ¼ÅŸÃ¼mler:
        *   `A.Resize(224, 224)`
        *   `A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))`
        *   `ToTensorV2()`

## Veri Seti Kurulumu

Bu proje, Kaggle Ã¼zerindeki [Beyin Kanseri MRI Veri Seti](https://www.kaggle.com/datasets/orvile/brain-cancer-mri-dataset) ile uyumlu olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r. Projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip ederek veri setini hazÄ±rlamanÄ±z gerekmektedir:

1.  **Veri Setini Ä°ndirme:**
    *   YukarÄ±daki Kaggle baÄŸlantÄ±sÄ±ndan "Brain Cancer MRI Dataset"i indirin.
    *   Ä°ndirilen zip dosyasÄ±nÄ± aÃ§Ä±n.

2.  **Veri KlasÃ¶rlerini DÃ¼zenleme:**
    *   Projenin kÃ¶k dizininde (README.md'nin bulunduÄŸu yerde) `data` adÄ±nda bir klasÃ¶r oluÅŸturun.
    *   Ä°ndirdiÄŸiniz veri setindeki sÄ±nÄ±f klasÃ¶rlerini (`brain_glioma`, `brain_menin`, `brain_tumor`) doÄŸrudan `data` klasÃ¶rÃ¼nÃ¼n altÄ±na yerleÅŸtirin. `train`, `val`, `test` alt klasÃ¶rlerini manuel olarak oluÅŸturmanÄ±za gerek yoktur; `preprocess_data.py` betiÄŸi bu ayrÄ±mÄ± otomatik olarak yapacaktÄ±r. Ã–rnek yapÄ±:
        ```
        BrainMRIModel/
        â”œâ”€â”€ data/
        â”‚   â”œâ”€â”€ brain_glioma/
        â”‚   â”œâ”€â”€ brain_menin/
        â”‚   â””â”€â”€ brain_tumor/
        ```
    *   Kaggle veri setindeki orijinal klasÃ¶r isimleri farklÄ± olabilir (`brain_glioma`, `brain_menin`,  `brain_tumor`). **Ancak, `preprocess_data.py` betiÄŸi bu isimleri projenin beklediÄŸi `0_glioma`, `1_menin`, `2_tumor` formatÄ±na otomatik olarak dÃ¶nÃ¼ÅŸtÃ¼recektir. Bu nedenle, manuel olarak yeniden adlandÄ±rmanÄ±za gerek yoktur.**

3.  **Veri Ã–n Ä°ÅŸleme ve `.npy` DÃ¶nÃ¼ÅŸtÃ¼rme:**
    *   Proje, eÄŸitim iÃ§in `preprocessed_data` klasÃ¶rlerinde `.npy` uzantÄ±lÄ± Ã¶n iÅŸlenmiÅŸ gÃ¶rÃ¼ntÃ¼ dosyalarÄ±nÄ± beklemektedir. `dataset/custom_dataset.py` dosyasÄ± bu `.npy` dosyalarÄ±nÄ± okur.
    *   **GÃ¼ncelleme:** ArtÄ±k bu iÅŸlem iÃ§in bir betik bulunmaktadÄ±r. Proje kÃ¶k dizininde `preprocess_data.py` adÄ±nda bir betik oluÅŸturulmuÅŸtur. Ham verileri `data` klasÃ¶rÃ¼ne yerleÅŸtirdikten sonra bu betiÄŸi Ã§alÄ±ÅŸtÄ±rarak `.npy` formatÄ±ndaki Ã¶n iÅŸlenmiÅŸ verileri `preprocessed_data` klasÃ¶rÃ¼ne otomatik olarak oluÅŸturabilirsiniz:
        ```bash
        python -m preprocess_data
        ```
    *   **Ã–nemli Not:** `.gitignore` dosyasÄ± `data/` ve `preprocessed_data/` klasÃ¶rlerini versiyon kontrolÃ¼nden hariÃ§ tutar. Bu klasÃ¶rleri projenin iÃ§ine indirip dÃ¼zenledikten sonra, Git deposuna yÃ¼klenmeyeceklerdir.

## YardÄ±mcÄ± Betikler

*   **`test.py`:** EÄŸitilmiÅŸ modelin test veri seti Ã¼zerindeki performansÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r. Hem en iyi modeli hem de SWA modelini test edebilir.
*   **`losses.py`:** Gelecekte Ã¶zel kayÄ±p fonksiyonlarÄ± eklemek iÃ§in yer tutucu.
*   **Renk Kodlu Konsol Ã‡Ä±ktÄ±sÄ±:** Terminal Ã§Ä±ktÄ±larÄ±nÄ± renklendirmek iÃ§in Ã¶zel ANSI kaÃ§Ä±ÅŸ kodlarÄ± kullanÄ±lÄ±r.
*   **Windows iÃ§in Ã‡oklu Ä°ÅŸlem DesteÄŸi:** `multiprocessing` modÃ¼lÃ¼, Windows iÅŸletim sistemlerinde uyumluluÄŸu saÄŸlamak iÃ§in yapÄ±landÄ±rÄ±lmÄ±ÅŸtÄ±r.

## BaÅŸlangÄ±Ã§

Projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼klemeniz ve ardÄ±ndan `models/train.py` betiÄŸini Ã§alÄ±ÅŸtÄ±rmanÄ±z yeterlidir.


# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin 
pip install -r requirements.txt

# Modeli eÄŸitin
python -m models.train

# Modeli test edin (eÄŸitimden sonra)
python -m test
```
~~python test.py
ğŸ” Veri yÃ¼kleniyor...
ğŸ¤– EÄŸitilmiÅŸ model models\full_vgg_custom.pt yÃ¼klendi.
ğŸ” Tahminler yapÄ±lÄ±yor...

ğŸ¯ 912 test Ã¶rneÄŸinden 891 tanesi doÄŸru tahmin edildi.
âœ… DoÄŸruluk OranÄ±: 97.70%
ğŸ“ˆ KarÄ±ÅŸÄ±klÄ±k Matrisi Ã§iziliyor...

SÄ±nÄ±flandÄ±rma Raporu:
              precision    recall  f1-score   support

    0_glioma       0.99      0.98      0.99       302
     1_menin       0.98      0.95      0.97       302
     2_tumor       0.96      1.00      0.98       308

    accuracy                           0.98       912
   macro avg       0.98      0.98      0.98       912
weighted avg       0.98      0.98      0.98       912
---
```

![FCwvqas.md.png](https://iili.io/FCwvqas.md.png)

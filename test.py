import os, random
import torch
from torch.utils.data import DataLoader, Subset
from dataset.custom_dataset import CustomTumorDataset
from models.basic_cnn_model import BasicCNNModel
from models.train import build_dataloaders # Only import build_dataloaders as Trainer is not used here
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report # Add classification_report
import numpy as np

# Device configuration
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Model ve veri yÃ¼kleme
print("ğŸ” Veri yÃ¼kleniyor...")
# CustomTumorDataset, iÃ§inde zaten resize, normalize ve ToTensorV2 dÃ¶nÃ¼ÅŸÃ¼mlerini uygular.
# train.py'deki build_dataloaders fonksiyonu da to_rgb=True ile Ã§aÄŸÄ±rÄ±r.
test_root = os.path.join("preprocessed_data", "test") # Dizininize gÃ¶re gÃ¼ncelleyin
test_dataset = CustomTumorDataset(test_root, to_rgb=True) # EÄŸitimdeki to_rgb ayarÄ±yla aynÄ± olmalÄ±

# Keras kodundaki gibi 1 000 rastgele Ã¶rnek seÃ§
num_samples = 912
if num_samples > len(test_dataset):
    print(f"Test seti {num_samples}'den kÃ¼Ã§Ã¼k! TÃ¼m test setini kullanÄ±lÄ±yor: {len(test_dataset)} Ã¶rnek.")
    num_samples = len(test_dataset)

indices = random.sample(range(len(test_dataset)), num_samples)
subset = Subset(test_dataset, indices)
test_loader = DataLoader(subset, batch_size=1, shuffle=False, num_workers=0, pin_memory=False) # Windows iÃ§in num_workers=0

# SÄ±nÄ±f isimlerini al (datasetten doÄŸrudan)
class_names = test_dataset.class_names

# 3 âŸ¶ EÄŸitilmiÅŸ modeli yÃ¼kleme
model = BasicCNNModel(num_classes=len(class_names), in_channels=3).to(DEVICE)
checkpoint_path = os.path.join("models", "full_vgg_custom.pt") # YÃ¼klenecek modelin yolu

if os.path.exists(checkpoint_path):
    state_dict = torch.load(checkpoint_path, map_location=DEVICE)
    model.load_state_dict(state_dict)

    # EÄŸitimdeki konfigÃ¼rasyonu geri getir:
    model.freeze_blocks_until(1)   # 0 ve 1 aÃ§Ä±k  â†’ opened_blocks = 2

    model.eval()          # âš ï¸ kritik: dropout/noise katmanlarÄ±nÄ± kapatÄ±r
    print(f"ğŸ¤– EÄŸitilmiÅŸ model {checkpoint_path} yÃ¼klendi.")
else:
    print(f"âŒ Model bulunamadÄ±: {checkpoint_path}. LÃ¼tfen Ã¶nce modeli eÄŸitin.")
    exit()

# 4 âŸ¶ Rastgele Ã¶rneklerde doÄŸruluk hesabÄ±
correct = 0
total = 0
all_preds, all_labels = [], []

print("ğŸ” Tahminler yapÄ±lÄ±yor...")
with torch.no_grad():           # gradyan gerekmez
    for imgs, labels in test_loader:
        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)

        outputs = model(imgs)
        preds = outputs.argmax(dim=1)

        total += labels.size(0)
        correct += (preds == labels).sum().item()

        all_preds.append(preds.item()) # batch_size=1 olduÄŸu iÃ§in item() kullanÄ±yoruz
        all_labels.append(labels.item()) # batch_size=1 olduÄŸu iÃ§in item() kullanÄ±yoruz

# DoÄŸruluk oranÄ± hesapla ve dÃ¼zgÃ¼n print et
accuracy = 100.0 * correct / total # total, dÃ¶ngÃ¼ iÃ§inde hesaplanÄ±yor
print(f"\nğŸ¯ {total} test Ã¶rneÄŸinden {correct} tanesi doÄŸru tahmin edildi.")
print(f"âœ… DoÄŸruluk OranÄ±: {accuracy:.2f}%")

# ğŸ“ˆ KarÄ±ÅŸÄ±klÄ±k Matrisi Ã‡izimi
print("ğŸ“ˆ KarÄ±ÅŸÄ±klÄ±k Matrisi Ã§iziliyor...")
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Tahmin Edilen Etiket')
plt.ylabel('GerÃ§ek Etiket')
plt.title('KarÄ±ÅŸÄ±klÄ±k Matrisi')
plt.show()

print("\nSÄ±nÄ±flandÄ±rma Raporu:")
print(classification_report(all_labels, all_preds, target_names=class_names))